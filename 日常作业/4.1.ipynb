import pandas as pd
import numpy as np

# 定义计算熵的函数
def entropy(data):
    classes, counts = np.unique(data, return_counts=True)
    probabilities = counts / len(data)
    return -np.sum(probabilities * np.log2(probabilities))

# 定义计算基尼指数的函数
def gini(data):
    classes, counts = np.unique(data, return_counts=True)
    probabilities = counts / len(data)
    return 1 - np.sum(probabilities ** 2)
# 创建示例数据表格
data = {
    '编号': [1, 2, 3, 4, 5],
    '年龄（岁）': [35,38,26,29,28],
    '身高（cm）': [176, 178, 172, 173, 174],
    '学历': ['本科', '硕士', '本科', '博士',  '本科'],
    '月薪（元）': [20000, 10000, 25000, 20000, 15000],
    '是否相亲': ['否', '是', '否', '是', '是']
}

df = pd.DataFrame(data)

# 按照年龄（大于等于29岁）切分数据集
left_subset = df[df['年龄（岁）'] >= 29]['是否相亲']
right_subset = df[df['年龄（岁）'] < 29]['是否相亲']

# 计算切分后的信息增益
total_entropy = entropy(df['是否相亲'])
left_entropy = entropy(left_subset)
right_entropy = entropy(right_subset)
weighted_entropy = (len(left_subset) / len(df)) * left_entropy + (len(right_subset) / len(df)) * right_entropy
information_gain = total_entropy - weighted_entropy

# 计算切分后的基尼指数
gini_left = gini(left_subset)
gini_right = gini(right_subset)
weighted_gini = (len(left_subset) / len(df)) * gini_left + (len(right_subset) / len(df)) * gini_right

print("I信息增益:", information_gain)
print("基尼指数:", weighted_gini)